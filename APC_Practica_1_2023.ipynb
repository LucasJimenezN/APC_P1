{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZMnmdDBCl7F"
   },
   "source": [
    "# Pràctica 1: Resolem un problema de classificacio\n",
    "\n",
    "## Objectius\n",
    "\n",
    "Els objectius d'aquesta pràctica són:\n",
    "\n",
    "* Aplicar els coneixements adquirits sobre classificacio, tecniques d'emplenats de nans i validacio creuada.\n",
    "  \n",
    "* Ser capac de comparar diferents models classificacio\n",
    "\n",
    "* Ser capac de fer busca d'hiperparametres.\n",
    "\n",
    "* Entendre i implamentar la validacio creuada\n",
    "\n",
    "* Analitzar detalladament els resultats obtinguts durant l'aprenentatge dels diferents models.\n",
    "\n",
    "Aquesta practica es previa al cas kaggle que realitzareu durant la segona part de l'assignatura. En aquesta primera practica les preguntes estan definides, pero us ha de servir d'aprenentatge alhora de saber com estructurar un projecte d'aprenentatge automatic ja que en el cas kaggle no tindreu les preguntes.\n",
    "\n",
    "## Bases de dades\n",
    "\n",
    "En aquesta practica farem servir la base de dades del titanic. L'atribut que predirem es Survived, el qual ens diu si va sobreviure o no cada passatger.\n",
    "\n",
    "\n",
    "https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "\n",
    "##Treball en grup\n",
    "Aquesta practica es treballara en grups de 2-3 persones. En casos excepcionals i degudament justificats la practica es podra realitzar de forma individual.\n",
    "## Seguiment i entrega de la pràctica\n",
    "\n",
    "En la pràctica 1, es presenten diverses tasques per fer una correcta comparativa dels resultats obtinguts per diversos mètodes de classificació numèrica en una mateixa base de dades.\n",
    "\n",
    "\n",
    "En aquesta practica es realitzara sessions de seguiment del treball. Aquestes sessions de treball està orientada a que els alumnes que vingueu pugueu preguntar i resoldre dubtes sobre les dades, preguntar sobre l'objectiu de cada apartat dels enunciats que no us hagi quedat clar, i preguntar sobre els resultats que esteu obtenint a l'hora d'analitzar les dades. Es molt recomanable venir amb el treball fet a clase per tal de poder comentar dubtes.\n",
    "\n",
    "Pel que fa l'entrega, caldra entregar per caronte el seguent:\n",
    "\n",
    "1. Memòria en format PDF o en la mateixa notebook explicant els resultats trobats sobre la bases de dades amb el respectiu codi de python. Aquesta nota es la mateixa per tots els membres del grup (9 pts)\n",
    "\n",
    "2. Presentació amb els resultats 4 min màxim. Aquesta nota es individual. (1 pt)\n",
    "\n",
    "Nota: En cas d'entregar la memoria com a PDF, caldra entregar el codi de python a part. Si s'entrega com a notebook, la mateixa notebook servira com a codi.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zdgsxfuCl7S"
   },
   "source": [
    "# Descripcio de la pràctica\n",
    "\n",
    "A continuacio es mostren tots els continguts que s'evaluara en la pràctica:\n",
    "\n",
    "1. EDA (exploratory data analysis) (1 punts):\n",
    "  * Analisi de tamany i tipologia de dades ( 0.25 pt)\n",
    "  * Primera valoracio de correlacions ( 0.5 pt)\n",
    "  * Analisi atribut target ( 0.25 pt)\n",
    "2. Preprocessing (2 punts):\n",
    "  * Eliminacio de nans (0.5 punts)\n",
    "  * Encoding de categoriques (0.75 punts)\n",
    "  * Altres (PCA, normalitzacio..)\n",
    "3. Metric selection (1.5 punts):\n",
    "  * Seleccio de la millor metrica pel problema (0.75 punts)\n",
    "  * Visualitzacio de ROC/AUC (0.75 punts)\n",
    "4. Model Selection amb Crossvalidation (4 punts):\n",
    "  * Seleccio del millor model (2 punts)\n",
    "  * Busqueda hiperparametres (2 punts)\n",
    "5. Analisi final (1.5 punt)\n",
    "\n",
    "Cal dir que, les puntuacions dins de cada apartat son orientatives. La pràctica esta construida a partir d'un seguit de preguntes orientatives en cada apartat les quals tenen relacio amb els continguts evaluables. **NO cal contestar-les totes**. Són una guia per a que reflexioneu i aprengueu detalls de cada apartat.  Es recomanable, aixo si, llegir totes les preguntes abans de realitzar la practica i tenir-les en ment alhora d'executar-la.\n",
    "\n",
    "\n",
    "**IMPORTANT**: El que es valorara en la practica es la capacitat de mantenir una narrativa coherent alhora que es realitzen els resultats. No es mirara tant que alguna pregunta quedi per respondre sino que els passos seguits en base als resultats obtinguts siguin coherents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuENGdYFCl7S"
   },
   "source": [
    "### 1. EDA (exploratory data analysis) (1 punt)\n",
    "\n",
    "Abans de res cal sempre veure com es la base de dades asignada?\n",
    "\n",
    "**Preguntes:**\n",
    "* Quants atributs té la vostra base de dades?\n",
    "* Quin tipus d'atributs tens? (Númerics, temporals, categorics, binaris...)\n",
    "* Com es el target, quantes categories diferents existeixen?\n",
    "* Tenim nans en les dades?\n",
    "* Podeu veure alguna correlació entre X i y?\n",
    "* Estan balancejades les etiquetes (distribució similar entre categories)? Creus que pot afectar a la classificació la seva distribució?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La nostra base de dades té 12 atributs.\n"
     ]
    }
   ],
   "source": [
    "# Llegim la base de dades\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Obtenim el numero d'atributs\n",
    "num_atr = df.shape[1]\n",
    "\n",
    "# Veiem quants atributs te el nostre csv\n",
    "print(f\"La nostra base de dades té {num_atr} atributs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veiem doncs que la nostra base de dades disposa de 12 atributs, els quals tenen els següents noms:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Els noms dels atributs son: \n",
      "PassengerId\n",
      "Survived\n",
      "Pclass\n",
      "Name\n",
      "Sex\n",
      "Age\n",
      "SibSp\n",
      "Parch\n",
      "Ticket\n",
      "Fare\n",
      "Cabin\n",
      "Embarked\n"
     ]
    }
   ],
   "source": [
    "atributos = df.columns.tolist()\n",
    "\n",
    "print(f\"Els noms dels atributs son: \")\n",
    "for nombre in atributos:\n",
    "    print(nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara ens interesa saber el tipus de dades que guarden aquests atributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Els tipus de dades dels atributs son:\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object.\n"
     ]
    }
   ],
   "source": [
    "atr_type = df.dtypes\n",
    "\n",
    "print(f\"Els tipus de dades dels atributs son:\\n{atr_type}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara ens interesa saber com es el target i quantes categories diferents existeixen:\n",
    "Despres de veure la base de dades, podem deduir que el nostre target a analitzar és la columna \"Survived\", la qual ens indica si el passatger va sobreviure (1) o no (0), veiem també que les diferents categories possibles(2) son 0, no sobreviu, 1 sobreviu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de categories que te l'atribut 'Survived' és: 2\n"
     ]
    }
   ],
   "source": [
    "num_categories_survived = df['Survived'].nunique()\n",
    "\n",
    "print(f\"El numero de categories que te l'atribut 'Survived' és: {num_categories_survived}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executant el codi python anterior, veiem que la nostra deducció de possibles valors categorics es correcte, i son 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara hem de determinar si la nostra base de dades te o no nans, això ho fariem de la següent manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La base de dades té nans.\n"
     ]
    }
   ],
   "source": [
    "df_nans = df.isna().any().any()\n",
    "\n",
    "if df_nans:\n",
    "    print(f\"La base de dades té nans.\")\n",
    "else:\n",
    "    print(f\"La base de dades no té nans.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara hem de veure si hi ha alguna corelació entre X i Y a la hora de determinar l'atribut \"Survived\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicamos la base de datos eliminando las columnas que no nos interesan.\n",
    "dataset_corr = df.copy()\n",
    "useless_columns = []\n",
    "\n",
    "for f in dataset_corr:\n",
    "    if f == 'Name' or f == 'Ticket' or f == 'Cabin':\n",
    "        useless_columns.append(f)\n",
    "\n",
    "dataset_corr.drop(useless_columns, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas Name , Ticket y Cabin por los motivos que especificamos a continuación:\n",
    "- Name: La eliminamos puesto que es un indicador del nombre del pasajero y no es relevante.\n",
    "- Ticket: La eliminamos puesto que es un indicador del ticket del pasajero y no es relevante.\n",
    "- Cabin: La eliminamos puesto que es un indicador de la cabina de cada pasajero y tampoco es relevante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los valores de sex a 0 y 1. ( codificación one-hot )\n",
    "df_encoded = pd.get_dummies(dataset_corr, columns=['Sex'], drop_first=True)\n",
    "\n",
    "# Convertimos los valores de Embarked.\n",
    "maping = {'C' : 0 , 'Q': 1, 'S' : 2}\n",
    "df_encoded['Embarked_numeric'] = df_encoded['Embarked'].map(maping)\n",
    "df_encoded = df_encoded.drop(columns=['Embarked'])\n",
    "\n",
    "# TODO: Preguntar mejor opción para la codificación ( encode )\n",
    "#df_encoded = pd.get_dummies(df_encoded, columns=['Embarked'], drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El codigo de arriba en primer lugar, eliminar la columna 'Sex', creando una llamada 'Sex_male', la cual es 1 si el usuario es hombre y 0 si mujer, de esta manera podremos calcular la correlación con 'Survived'. En segundo lugar, hemos eliminado la columna 'Embarked', creando la columna 'Embarked_numeric', que sustituie los valores C, Q y S, por 0, 1, 2 respectivamente, consiguiendo así poder calcular la correlación.\n",
    "A continuación se muestra como queda la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Sex_male  \\\n",
      "0              1         0       3  22.0      1      0   7.2500         1   \n",
      "1              2         1       1  38.0      1      0  71.2833         0   \n",
      "2              3         1       3  26.0      0      0   7.9250         0   \n",
      "3              4         1       1  35.0      1      0  53.1000         0   \n",
      "4              5         0       3  35.0      0      0   8.0500         1   \n",
      "..           ...       ...     ...   ...    ...    ...      ...       ...   \n",
      "886          887         0       2  27.0      0      0  13.0000         1   \n",
      "887          888         1       1  19.0      0      0  30.0000         0   \n",
      "888          889         0       3   NaN      1      2  23.4500         0   \n",
      "889          890         1       1  26.0      0      0  30.0000         1   \n",
      "890          891         0       3  32.0      0      0   7.7500         1   \n",
      "\n",
      "     Embarked_numeric  \n",
      "0                 2.0  \n",
      "1                 0.0  \n",
      "2                 2.0  \n",
      "3                 2.0  \n",
      "4                 2.0  \n",
      "..                ...  \n",
      "886               2.0  \n",
      "887               2.0  \n",
      "888               2.0  \n",
      "889               0.0  \n",
      "890               1.0  \n",
      "\n",
      "[891 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos hecho las modificaciones pertinentes a nuesta base de datos, ya podemos caluclar la correlación con la variable 'Survived'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pclass': -0.3384810359610148, 'Age': -0.07722109457217755, 'SibSp': -0.035322498885735576, 'Parch': 0.0816294070834836, 'Fare': 0.2573065223849622, 'Sex_male': -0.5433513806577547, 'Embarked_numeric': -0.16971767716412958}\n"
     ]
    }
   ],
   "source": [
    "new_names = df_encoded.columns.to_list()\n",
    "\n",
    "corr = {}\n",
    "for name in new_names: \n",
    "    if name == 'Survived' or name == 'PassengerId':\n",
    "        pass\n",
    "    else:\n",
    "        corr_value = df_encoded['Survived'].corr(df_encoded[name])\n",
    "        corr[name] = corr_value\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos los resultados pasamos a analizarlos:\n",
    "- Pclass: -0,338\n",
    "    - Esta correlación es negativa y moderadamente fuerte. Indica que a medida de que Pclass disminuye ( lo que significa que el pasajero está en una clase mas alta ) la probabilidad de sobrevivir aumenta.\n",
    "- Age: -0,077\n",
    "    - Esta correlación es negativa y bastante baja. Lo que indica que a medida que la edad del pasajero aumenta, la probabilidad de sobrebirir del pasajero disminuye ligeramente. Pero como lo correlación es bastante baja podemos deducir que este no es un factor determinante.\n",
    "- SibSp: -0.035\n",
    "    - Esta correlación también es negativa y bastante baja. Indica que a medida que el numero de hermanos o cónyuges a bordo aumenta, la probabilidad de sobrevivir disminuye ligeramente. Como la correlación es bastante baja podemos deducir que no es un factor determinante.\n",
    "- Parch: 0,082\n",
    "    - Esta correlación es positiva y bastante baja. Indica que a medida que el numero padres o hijos a bordo aumenta, la posibilidad de sobrevivir aumenta ligeramnete. Como la correlación es bastante baja podemos deducir que no es un factor determinante.\n",
    "- Fare: 0.257\n",
    "    - Esta correlación es positiva y relativamente fuerte. Indica que a medida que el coste del billete aumenta, la posibilidad de sobrevivir aumente moderadamente. Como esta correlación es moderada podemos deducir que puede ser un factor determinante, puesto que los pasageros que havian pagado mas, quizas tenian prioridad a la hora de ser rescatados.\n",
    "- Sex_male: -0,543\n",
    "    - Esta correlación es negativa y fuerte. Indica que a ser del sexo masculino, disminuia drasticamente las posibilidades de sobrevivir, por lo que, las mujeres, tenian prioridad a la hora del rescate. Esta correlación al ser bastante fuerte podemos decir que es un factor determinante de la supervivencia del pasagero.\n",
    "- Embarked_numeric: -0,170\n",
    "    - Esta correlación es negativa y moderadamente baja. Indica que el puerto de embarque está asociado a la probabilidad de sobrevivir, pero al ser moderadamente baja, no es un factor determinante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos analizado la correlación, necesitamos saber si las etiquetas están balanceadas y si puede afectar a la clasificación su distribución.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuLtWQWpCl7T"
   },
   "source": [
    "### 2. Preprocessing (normalitzation, outlier removal, feature selection..) (2 punts)\n",
    "Un cop vistes les dades de les que es disposa, cal preparar les dades per als nostres algoritmes. Segons la tipologia de dades, es poden filtrar atributs, aplicar-hi reductors de dimensionalitat, codificar categories textuals en valors numèrics, normalitzar les dades, treure outliers...\n",
    "\n",
    "Navegueu per la [documentació de sklearn sobre preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) per tal de trobar les diferents opcions que proporciona sklearn.\n",
    "\n",
    "**Preguntes:**\n",
    "* Estàn les dades normalitzades? Caldria fer-ho?\n",
    "* En cas que les normalitzeu, quin tipus de normalització será més adient per les vostres dades?\n",
    "* Teniu gaires dades sense informació (nans)? Tingueu en compte que hi ha metodes que no els toleren durant el aprenentatge. Com afecta a la classificació si les filtrem? I si les reompliu? Com ho farieu? [Pista](https://scikit-learn.org/stable/modules/impute.html)\n",
    "* Teniu dades categoriques? Quina seria la codificació amb més sentit?\n",
    "* Podreu treure algun atribut extra de les categoriques (per exemple, aplicant alguna regla sobre el text)?\n",
    "* Caldria aplicar PCA? Quins beneficis o inconvenients trobarieu?\n",
    "* Caldria aplicar alguna tecnica de seleccio de features? Ho trobeu necessari?\n",
    "* Es poden aplicar PolynomialFeatures per millorar la classificació? En quins models té sentit fer-ho?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axc-wn2rCl7T"
   },
   "source": [
    "### 3. Metric selection (1.5 punts)\n",
    "En aquest apartat ens centrarem en les mètriques de classificació ([documentació](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)). Per a fer-ho, entreneu una regressio logistica (no cal separar train-test) i a partir d'aquesta generarem una serie de funcions per analitzar els nostres resultats . Aquestes funcions ens serviran mes endevant. Caldra tambe triar la metrica que farem servir despres per triar el millor model.\n",
    "\n",
    "**Preguntes:**\n",
    "* A teoria, hem vist el resultat d'aplicar el `accuracy_score` sobre dades no balancejades. Podrieu explicar i justificar quina de les següents mètriques será la més adient pel vostre problema? `accuracy_score`, `f1_score` o `average_precision_score`?\n",
    "* Abans de comencar a entrenar models, genereu una suite de funcions per poder analitzar graficament com esta anant el vostre model. Mostreu la Precisió-Recall Curve i la ROC Curve. Quina és més rellevant pel vostre dataset? Expliqueu amb les vostres paraules, la diferencia entre una i altre [Pista](https://stats.stackexchange.com/questions/338826/auprc-vs-auc-roc)\n",
    "* Què mostra [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)? Quina métrica us fixareu per tal de optimitzar-ne la classificació pel vostre cas?\n",
    "\n",
    "Nota: Fixeu-vos que en aquest apartat NO ES VALOREN ELS RESULTATS. L'unic que es valora es l'eleccio de la metrica de classificacio aixi com saber quin tipus de grafiques fer per analitzar els resultats. Abans de solucionar un problema cal tenir molt clar la metrica d'error que es fara servir, i es una decisio que cal pendre previa a entrenar models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8xe5r78Cl7T"
   },
   "source": [
    "### 4. Model Selection amb validacio creuada (4 punts)\n",
    "\n",
    "Fent servir la metrica trobada en l'apartat anterior, en aquest apartat caldra seleccionar una serie de models i, fent us de la validacio creuada, seleccionar el millor model amb els seus respectius millors hyperparametres que haurem buscat fent hyperparameter search.\n",
    "\n",
    "La tasca d'aquesta pràctica s'enmarca dins l'aprenentatge computacional **supervisat**. A sklearn, disposem de varies tècniques [(veure documentació)](https://scikit-learn.org/stable/supervised_learning.html). A les classes de teoria, hem vist varies tècniques, com ara logistic regression, SVM amb diferents kernels, Nearest Neighbour... i tambe coneixeu altres tecniques d'altres cursos, com els arbres de decisio. Ademes, en la classe de problemes hem donat tambe els random forest i els gradient boosting. Per aquest apartat es demana seleccionar **un minim de 4 models** (per exemple, regressio logistica, random forest, KNN, SVM).\n",
    "\n",
    "**Preguntes:**\n",
    "* Quins models heu considerat? Perque els heu seleccionat?\n",
    "* Fent servir validacio creuada, escolliu el millor model (agafant els hiperparamtres per defecte). Recordeu fer servir la metrica utilitzada en l'apartat anterior. Perque es important fer servir validacio creuada? Heu de fer servir algun [tipus de validacio creuada](https://scikit-learn.org/stable/modules/cross_validation.html) en especial?\n",
    "\n",
    "* Seleccioneu una serie d'hyperparametres a provar per cadascun dels models i realitzeu una cerca d'hyperparametres. Hi ha algun model que creieu que podeu descartar de primeres? Perque?\n",
    "\n",
    "* Mostreu els resultats en una taula on es mostri el model, els experiments realitzats i els resultats obtinguts (tant en train com en test). Podeu mostrar tambe el temps d'entrenament de cada model.\n",
    "\n",
    "* Quin tipus de K-fold heu escollit en la seleccio de models? I en la seleccio de models amb hyperparametres? Com afecta al resultat modificar el numero de k (numero de folds) al resultat?\n",
    "\n",
    "* Quines formes de buscar el millor parametre heu trobat? Són costoses computacionalment parlant? [documentació](https://scikit-learn.org/stable/modules/grid_search.html) Quina heu seleccionat?\n",
    "\n",
    "* Si disposem de recursos limitats (per exemple, un PC durant 1 hora) quin dels métodes creieu que obtindrà millor resultat final?\n",
    "\n",
    "* Existeixen altres mètodes de búsqueda més eficients ([scikit-optimize](https://scikit-optimize.github.io/stable/))?\n",
    "\n",
    "* Opcional : Feu la prova, i amb el model i el metode de crossvalidació escollit, configureu els diferents metodes de búsqueda per a que s'executin durant el mateix temps (i.e. depenent del problema, 0,5h-1 hora). Analitzeu quin ha arribat a una millor solució. (Ajuda: estimeu el temps que trigarà a fer 1 training el vostre model, i aixi trobeu el número de intents que podeu fer en cada cas.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hx-3b7v2TwJ3"
   },
   "source": [
    "### 5.Analisi Final (1.5 punt)\n",
    "\n",
    "Un cop seleccionat el millor model amb els millors hiperparamtres, caldra fer un report final amb els resultats obtinguts.\n",
    "\n",
    "Preguntes:\n",
    "* Mostreu les curves ROC/PR (la que hageu escollit en l'apartat 2) i interpreteu els resultats.\n",
    "\n",
    "* Analitzeu en detall les diferents metriques que trobeu adients i comenteu per sobre com podrieu fer servir aquest model en un futur. Aixo es el que es coneix com un cas d'us.\n",
    "\n",
    "* Com creieu que es podria millorar el vostre model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJlr4sZkU0s-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
