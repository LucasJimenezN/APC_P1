{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZMnmdDBCl7F"
   },
   "source": [
    "# Pràctica 1: Resolem un problema de classificacio\n",
    "\n",
    "## Objectius\n",
    "\n",
    "Els objectius d'aquesta pràctica són:\n",
    "\n",
    "* Aplicar els coneixements adquirits sobre classificacio, tecniques d'emplenats de nans i validacio creuada.\n",
    "  \n",
    "* Ser capac de comparar diferents models classificacio\n",
    "\n",
    "* Ser capac de fer busca d'hiperparametres.\n",
    "\n",
    "* Entendre i implamentar la validacio creuada\n",
    "\n",
    "* Analitzar detalladament els resultats obtinguts durant l'aprenentatge dels diferents models.\n",
    "\n",
    "Aquesta practica es previa al cas kaggle que realitzareu durant la segona part de l'assignatura. En aquesta primera practica les preguntes estan definides, pero us ha de servir d'aprenentatge alhora de saber com estructurar un projecte d'aprenentatge automatic ja que en el cas kaggle no tindreu les preguntes.\n",
    "\n",
    "## Bases de dades\n",
    "\n",
    "En aquesta practica farem servir la base de dades del titanic. L'atribut que predirem es Survived, el qual ens diu si va sobreviure o no cada passatger.\n",
    "\n",
    "\n",
    "https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "\n",
    "##Treball en grup\n",
    "Aquesta practica es treballara en grups de 2-3 persones. En casos excepcionals i degudament justificats la practica es podra realitzar de forma individual.\n",
    "## Seguiment i entrega de la pràctica\n",
    "\n",
    "En la pràctica 1, es presenten diverses tasques per fer una correcta comparativa dels resultats obtinguts per diversos mètodes de classificació numèrica en una mateixa base de dades.\n",
    "\n",
    "\n",
    "En aquesta practica es realitzara sessions de seguiment del treball. Aquestes sessions de treball està orientada a que els alumnes que vingueu pugueu preguntar i resoldre dubtes sobre les dades, preguntar sobre l'objectiu de cada apartat dels enunciats que no us hagi quedat clar, i preguntar sobre els resultats que esteu obtenint a l'hora d'analitzar les dades. Es molt recomanable venir amb el treball fet a clase per tal de poder comentar dubtes.\n",
    "\n",
    "Pel que fa l'entrega, caldra entregar per caronte el seguent:\n",
    "\n",
    "1. Memòria en format PDF o en la mateixa notebook explicant els resultats trobats sobre la bases de dades amb el respectiu codi de python. Aquesta nota es la mateixa per tots els membres del grup (9 pts)\n",
    "\n",
    "2. Presentació amb els resultats 4 min màxim. Aquesta nota es individual. (1 pt)\n",
    "\n",
    "Nota: En cas d'entregar la memoria com a PDF, caldra entregar el codi de python a part. Si s'entrega com a notebook, la mateixa notebook servira com a codi.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zdgsxfuCl7S"
   },
   "source": [
    "# Descripcio de la pràctica\n",
    "\n",
    "A continuacio es mostren tots els continguts que s'evaluara en la pràctica:\n",
    "\n",
    "1. EDA (exploratory data analysis) (1 punts):\n",
    "  * Analisi de tamany i tipologia de dades ( 0.25 pt)\n",
    "  * Primera valoracio de correlacions ( 0.5 pt)\n",
    "  * Analisi atribut target ( 0.25 pt)\n",
    "2. Preprocessing (2 punts):\n",
    "  * Eliminacio de nans (0.5 punts)\n",
    "  * Encoding de categoriques (0.75 punts)\n",
    "  * Altres (PCA, normalitzacio..)\n",
    "3. Metric selection (1.5 punts):\n",
    "  * Seleccio de la millor metrica pel problema (0.75 punts)\n",
    "  * Visualitzacio de ROC/AUC (0.75 punts)\n",
    "4. Model Selection amb Crossvalidation (4 punts):\n",
    "  * Seleccio del millor model (2 punts)\n",
    "  * Busqueda hiperparametres (2 punts)\n",
    "5. Analisi final (1.5 punt)\n",
    "\n",
    "Cal dir que, les puntuacions dins de cada apartat son orientatives. La pràctica esta construida a partir d'un seguit de preguntes orientatives en cada apartat les quals tenen relacio amb els continguts evaluables. **NO cal contestar-les totes**. Són una guia per a que reflexioneu i aprengueu detalls de cada apartat.  Es recomanable, aixo si, llegir totes les preguntes abans de realitzar la practica i tenir-les en ment alhora d'executar-la.\n",
    "\n",
    "\n",
    "**IMPORTANT**: El que es valorara en la practica es la capacitat de mantenir una narrativa coherent alhora que es realitzen els resultats. No es mirara tant que alguna pregunta quedi per respondre sino que els passos seguits en base als resultats obtinguts siguin coherents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuENGdYFCl7S"
   },
   "source": [
    "### 1. EDA (exploratory data analysis) (1 punt)\n",
    "\n",
    "Abans de res cal sempre veure com es la base de dades asignada?\n",
    "\n",
    "**Preguntes:**\n",
    "* Quants atributs té la vostra base de dades?\n",
    "* Quin tipus d'atributs tens? (Númerics, temporals, categorics, binaris...)\n",
    "* Com es el target, quantes categories diferents existeixen?\n",
    "* Tenim nans en les dades?\n",
    "* Podeu veure alguna correlació entre X i y?\n",
    "* Estan balancejades les etiquetes (distribució similar entre categories)? Creus que pot afectar a la classificació la seva distribució?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La nostra base de dades té 12 atributs.\n"
     ]
    }
   ],
   "source": [
    "# Llegim la base de dades\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Obtenim el numero d'atributs\n",
    "num_atr = df.shape[1]\n",
    "\n",
    "# Veiem quants atributs te el nostre csv\n",
    "print(f\"La nostra base de dades té {num_atr} atributs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veiem doncs que la nostra base de dades disposa de 12 atributs, els quals tenen els següents noms:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Els noms dels atributs son: \n",
      "PassengerId\n",
      "Survived\n",
      "Pclass\n",
      "Name\n",
      "Sex\n",
      "Age\n",
      "SibSp\n",
      "Parch\n",
      "Ticket\n",
      "Fare\n",
      "Cabin\n",
      "Embarked\n"
     ]
    }
   ],
   "source": [
    "atributos = df.columns.tolist()\n",
    "\n",
    "print(f\"Els noms dels atributs son: \")\n",
    "for nombre in atributos:\n",
    "    print(nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara ens interesa saber el tipus de dades que guarden aquests atributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Els tipus de dades dels atributs son:\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object.\n"
     ]
    }
   ],
   "source": [
    "atr_type = df.dtypes\n",
    "\n",
    "print(f\"Els tipus de dades dels atributs son:\\n{atr_type}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara ens interesa saber com es el target i quantes categories diferents existeixen:\n",
    "Despres de veure la base de dades, podem deduir que el nostre target a analitzar és la columna \"Survived\", la qual ens indica si el passatger va sobreviure (1) o no (0), veiem també que les diferents categories possibles(2) son 0, no sobreviu, 1 sobreviu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de categories que te l'atribut 'Survived' és: 2\n"
     ]
    }
   ],
   "source": [
    "num_categories_survived = df['Survived'].nunique()\n",
    "\n",
    "print(f\"El numero de categories que te l'atribut 'Survived' és: {num_categories_survived}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara hem de determinar si la nostra base de dades te o no nans, això ho fariem de la següent manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La base de dades té nans.\n"
     ]
    }
   ],
   "source": [
    "df_nans = df.isna().any().any()\n",
    "\n",
    "if df_nans:\n",
    "    print(f\"La base de dades té nans.\")\n",
    "else:\n",
    "    print(f\"La base de dades no té nans.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara hem de veure si hi ha alguna corelació entre X i Y a la hora de determinar l'atribut \"Survived\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId tiene nans, por lo que no se puede calcular los nans.\n",
      "Survived tiene nans, por lo que no se puede calcular los nans.\n",
      "Pclass tiene nans, por lo que no se puede calcular los nans.\n",
      "Name tiene nans, por lo que no se puede calcular los nans.\n",
      "Sex tiene nans, por lo que no se puede calcular los nans.\n",
      "La correlació entre Age i Survived es: -0.07722109457217756.\n",
      "SibSp tiene nans, por lo que no se puede calcular los nans.\n",
      "Parch tiene nans, por lo que no se puede calcular los nans.\n",
      "Ticket tiene nans, por lo que no se puede calcular los nans.\n",
      "Fare tiene nans, por lo que no se puede calcular los nans.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/lucasjimeneznunez/Desktop/UAB/4t/APC/Practiques/P1/APC_Practica_1_2023.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucasjimeneznunez/Desktop/UAB/4t/APC/Practiques/P1/APC_Practica_1_2023.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m is_nan \u001b[39m=\u001b[39m df[nombre]\u001b[39m.\u001b[39misna()\u001b[39m.\u001b[39many()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucasjimeneznunez/Desktop/UAB/4t/APC/Practiques/P1/APC_Practica_1_2023.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m is_nan:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lucasjimeneznunez/Desktop/UAB/4t/APC/Practiques/P1/APC_Practica_1_2023.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     corr_surv \u001b[39m=\u001b[39m df[nombre]\u001b[39m.\u001b[39mcorr(df[\u001b[39m'\u001b[39m\u001b[39mSurvived\u001b[39m\u001b[39m'\u001b[39m])    \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucasjimeneznunez/Desktop/UAB/4t/APC/Practiques/P1/APC_Practica_1_2023.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLa correlació entre \u001b[39m\u001b[39m{\u001b[39;00mnombre\u001b[39m}\u001b[39;00m\u001b[39m i Survived es: \u001b[39m\u001b[39m{\u001b[39;00mcorr_surv\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lucasjimeneznunez/Desktop/UAB/4t/APC/Practiques/P1/APC_Practica_1_2023.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:2760\u001b[0m, in \u001b[0;36mSeries.corr\u001b[0;34m(self, other, method, min_periods)\u001b[0m\n\u001b[1;32m   2757\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m   2759\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mspearman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkendall\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m \u001b[39mcallable\u001b[39m(method):\n\u001b[0;32m-> 2760\u001b[0m     \u001b[39mreturn\u001b[39;00m nanops\u001b[39m.\u001b[39mnancorr(\n\u001b[1;32m   2761\u001b[0m         this\u001b[39m.\u001b[39mvalues, other\u001b[39m.\u001b[39mvalues, method\u001b[39m=\u001b[39mmethod, min_periods\u001b[39m=\u001b[39mmin_periods\n\u001b[1;32m   2762\u001b[0m     )\n\u001b[1;32m   2764\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2765\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmethod must be either \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2766\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mspearman\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mkendall\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or a callable, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2767\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmethod\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was supplied\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2768\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     94\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:1554\u001b[0m, in \u001b[0;36mnancorr\u001b[0;34m(a, b, method, min_periods)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m   1553\u001b[0m f \u001b[39m=\u001b[39m get_corr_func(method)\n\u001b[0;32m-> 1554\u001b[0m \u001b[39mreturn\u001b[39;00m f(a, b)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:1575\u001b[0m, in \u001b[0;36mget_corr_func.<locals>.func\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   1574\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(a, b):\n\u001b[0;32m-> 1575\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mcorrcoef(a, b)[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:2846\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   2842\u001b[0m \u001b[39mif\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39mor\u001b[39;00m ddof \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue:\n\u001b[1;32m   2843\u001b[0m     \u001b[39m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[1;32m   2844\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mbias and ddof have no effect and are deprecated\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2845\u001b[0m                   \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m-> 2846\u001b[0m c \u001b[39m=\u001b[39m cov(x, y, rowvar, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m   2847\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2848\u001b[0m     d \u001b[39m=\u001b[39m diag(c)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:2681\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2678\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2679\u001b[0m         w \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m aweights\n\u001b[0;32m-> 2681\u001b[0m avg, w_sum \u001b[39m=\u001b[39m average(X, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, weights\u001b[39m=\u001b[39mw, returned\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   2682\u001b[0m w_sum \u001b[39m=\u001b[39m w_sum[\u001b[39m0\u001b[39m]\n\u001b[1;32m   2684\u001b[0m \u001b[39m# Determine the normalization\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:518\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    515\u001b[0m     keepdims_kw \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims}\n\u001b[1;32m    517\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     avg \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mmean(axis, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkeepdims_kw)\n\u001b[1;32m    519\u001b[0m     avg_as_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(avg)\n\u001b[1;32m    520\u001b[0m     scl \u001b[39m=\u001b[39m avg_as_array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype(a\u001b[39m.\u001b[39msize\u001b[39m/\u001b[39mavg_as_array\u001b[39m.\u001b[39msize)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:184\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, mu\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    183\u001b[0m     \u001b[39mwith\u001b[39;00m _no_nep50_warning():\n\u001b[0;32m--> 184\u001b[0m         ret \u001b[39m=\u001b[39m um\u001b[39m.\u001b[39mtrue_divide(\n\u001b[1;32m    185\u001b[0m                 ret, rcount, out\u001b[39m=\u001b[39mret, casting\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m'\u001b[39m, subok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    186\u001b[0m     \u001b[39mif\u001b[39;00m is_float16_result \u001b[39mand\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m         ret \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype(ret)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "for nombre in atributos:\n",
    "    is_nan = df[nombre].isna().any()\n",
    "    if is_nan:\n",
    "        corr_surv = df[nombre].corr(df['Survived'])    \n",
    "        print(f\"La correlació entre {nombre} i Survived es: {corr_surv}.\")\n",
    "    else:\n",
    "        print(f\"{nombre} tiene nans, por lo que no se puede calcular los nans.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executant el codi python anterior, veiem que la nostra deducció de possibles valors categorics es correcte, i son 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuLtWQWpCl7T"
   },
   "source": [
    "### 2. Preprocessing (normalitzation, outlier removal, feature selection..) (2 punts)\n",
    "Un cop vistes les dades de les que es disposa, cal preparar les dades per als nostres algoritmes. Segons la tipologia de dades, es poden filtrar atributs, aplicar-hi reductors de dimensionalitat, codificar categories textuals en valors numèrics, normalitzar les dades, treure outliers...\n",
    "\n",
    "Navegueu per la [documentació de sklearn sobre preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) per tal de trobar les diferents opcions que proporciona sklearn.\n",
    "\n",
    "**Preguntes:**\n",
    "* Estàn les dades normalitzades? Caldria fer-ho?\n",
    "* En cas que les normalitzeu, quin tipus de normalització será més adient per les vostres dades?\n",
    "* Teniu gaires dades sense informació (nans)? Tingueu en compte que hi ha metodes que no els toleren durant el aprenentatge. Com afecta a la classificació si les filtrem? I si les reompliu? Com ho farieu? [Pista](https://scikit-learn.org/stable/modules/impute.html)\n",
    "* Teniu dades categoriques? Quina seria la codificació amb més sentit?\n",
    "* Podreu treure algun atribut extra de les categoriques (per exemple, aplicant alguna regla sobre el text)?\n",
    "* Caldria aplicar PCA? Quins beneficis o inconvenients trobarieu?\n",
    "* Caldria aplicar alguna tecnica de seleccio de features? Ho trobeu necessari?\n",
    "* Es poden aplicar PolynomialFeatures per millorar la classificació? En quins models té sentit fer-ho?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axc-wn2rCl7T"
   },
   "source": [
    "### 3. Metric selection (1.5 punts)\n",
    "En aquest apartat ens centrarem en les mètriques de classificació ([documentació](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)). Per a fer-ho, entreneu una regressio logistica (no cal separar train-test) i a partir d'aquesta generarem una serie de funcions per analitzar els nostres resultats . Aquestes funcions ens serviran mes endevant. Caldra tambe triar la metrica que farem servir despres per triar el millor model.\n",
    "\n",
    "**Preguntes:**\n",
    "* A teoria, hem vist el resultat d'aplicar el `accuracy_score` sobre dades no balancejades. Podrieu explicar i justificar quina de les següents mètriques será la més adient pel vostre problema? `accuracy_score`, `f1_score` o `average_precision_score`?\n",
    "* Abans de comencar a entrenar models, genereu una suite de funcions per poder analitzar graficament com esta anant el vostre model. Mostreu la Precisió-Recall Curve i la ROC Curve. Quina és més rellevant pel vostre dataset? Expliqueu amb les vostres paraules, la diferencia entre una i altre [Pista](https://stats.stackexchange.com/questions/338826/auprc-vs-auc-roc)\n",
    "* Què mostra [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)? Quina métrica us fixareu per tal de optimitzar-ne la classificació pel vostre cas?\n",
    "\n",
    "Nota: Fixeu-vos que en aquest apartat NO ES VALOREN ELS RESULTATS. L'unic que es valora es l'eleccio de la metrica de classificacio aixi com saber quin tipus de grafiques fer per analitzar els resultats. Abans de solucionar un problema cal tenir molt clar la metrica d'error que es fara servir, i es una decisio que cal pendre previa a entrenar models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8xe5r78Cl7T"
   },
   "source": [
    "### 4. Model Selection amb validacio creuada (4 punts)\n",
    "\n",
    "Fent servir la metrica trobada en l'apartat anterior, en aquest apartat caldra seleccionar una serie de models i, fent us de la validacio creuada, seleccionar el millor model amb els seus respectius millors hyperparametres que haurem buscat fent hyperparameter search.\n",
    "\n",
    "La tasca d'aquesta pràctica s'enmarca dins l'aprenentatge computacional **supervisat**. A sklearn, disposem de varies tècniques [(veure documentació)](https://scikit-learn.org/stable/supervised_learning.html). A les classes de teoria, hem vist varies tècniques, com ara logistic regression, SVM amb diferents kernels, Nearest Neighbour... i tambe coneixeu altres tecniques d'altres cursos, com els arbres de decisio. Ademes, en la classe de problemes hem donat tambe els random forest i els gradient boosting. Per aquest apartat es demana seleccionar **un minim de 4 models** (per exemple, regressio logistica, random forest, KNN, SVM).\n",
    "\n",
    "**Preguntes:**\n",
    "* Quins models heu considerat? Perque els heu seleccionat?\n",
    "* Fent servir validacio creuada, escolliu el millor model (agafant els hiperparamtres per defecte). Recordeu fer servir la metrica utilitzada en l'apartat anterior. Perque es important fer servir validacio creuada? Heu de fer servir algun [tipus de validacio creuada](https://scikit-learn.org/stable/modules/cross_validation.html) en especial?\n",
    "\n",
    "* Seleccioneu una serie d'hyperparametres a provar per cadascun dels models i realitzeu una cerca d'hyperparametres. Hi ha algun model que creieu que podeu descartar de primeres? Perque?\n",
    "\n",
    "* Mostreu els resultats en una taula on es mostri el model, els experiments realitzats i els resultats obtinguts (tant en train com en test). Podeu mostrar tambe el temps d'entrenament de cada model.\n",
    "\n",
    "* Quin tipus de K-fold heu escollit en la seleccio de models? I en la seleccio de models amb hyperparametres? Com afecta al resultat modificar el numero de k (numero de folds) al resultat?\n",
    "\n",
    "* Quines formes de buscar el millor parametre heu trobat? Són costoses computacionalment parlant? [documentació](https://scikit-learn.org/stable/modules/grid_search.html) Quina heu seleccionat?\n",
    "\n",
    "* Si disposem de recursos limitats (per exemple, un PC durant 1 hora) quin dels métodes creieu que obtindrà millor resultat final?\n",
    "\n",
    "* Existeixen altres mètodes de búsqueda més eficients ([scikit-optimize](https://scikit-optimize.github.io/stable/))?\n",
    "\n",
    "* Opcional : Feu la prova, i amb el model i el metode de crossvalidació escollit, configureu els diferents metodes de búsqueda per a que s'executin durant el mateix temps (i.e. depenent del problema, 0,5h-1 hora). Analitzeu quin ha arribat a una millor solució. (Ajuda: estimeu el temps que trigarà a fer 1 training el vostre model, i aixi trobeu el número de intents que podeu fer en cada cas.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hx-3b7v2TwJ3"
   },
   "source": [
    "### 5.Analisi Final (1.5 punt)\n",
    "\n",
    "Un cop seleccionat el millor model amb els millors hiperparamtres, caldra fer un report final amb els resultats obtinguts.\n",
    "\n",
    "Preguntes:\n",
    "* Mostreu les curves ROC/PR (la que hageu escollit en l'apartat 2) i interpreteu els resultats.\n",
    "\n",
    "* Analitzeu en detall les diferents metriques que trobeu adients i comenteu per sobre com podrieu fer servir aquest model en un futur. Aixo es el que es coneix com un cas d'us.\n",
    "\n",
    "* Com creieu que es podria millorar el vostre model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJlr4sZkU0s-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
